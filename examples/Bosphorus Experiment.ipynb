{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy.io\n",
      "import numpy as np\n",
      "from pybug.transform import SimilarityTransform, Translation\n",
      "from pybug.lucaskanade.image import ImageInverseCompositional\n",
      "from pybug.image import MaskedNDImage, BooleanNDImage\n",
      "import matplotlib.pyplot as plt\n",
      "from collections import OrderedDict\n",
      "from pybug.shape import PointCloud\n",
      "from pybug.io import auto_import\n",
      "import os"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def rms_point_error(original_box, transformed_box):\n",
      "    return np.sqrt(np.mean((original_box.points - transformed_box.points) ** 2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def build_normal_image(image):\n",
      "    n_image = MaskedNDImage.blank(image.shape, mask=image.mask, n_channels=3)\n",
      "    n_image.from_vector_inplace(image.mesh.vertex_normals.ravel())\n",
      "    return n_image"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.lucaskanade import LSIntensity\n",
      "\n",
      "def get_residual(option):\n",
      "    if option == 'DEPTH':\n",
      "        return (lambda x: x, LSIntensity())\n",
      "    elif option == 'NORMAL':\n",
      "        return (build_normal_image, LSIntensity())\n",
      "    else:\n",
      "        raise ValueError('Unknown algorithm option')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def my_test_affine(tdata, pt_offsets, alg_list, n_iters, n_freq_tests, spatial_sigma, verbose):\n",
      "    results = {}\n",
      "    \n",
      "    bounds_height = tdata.bounds_height\n",
      "    bounds_width = tdata.bounds_width\n",
      "    bounds = tdata.bounds\n",
      "    img = tdata.img\n",
      "    template = tdata.template\n",
      "    \n",
      "    # The box that the face lives in (not offset to correct position)\n",
      "    original_box = PointCloud(np.array([[0,             0],\n",
      "                                        [bounds_height, 0],\n",
      "                                        [bounds_height, bounds_width],\n",
      "                                        [0,             bounds_width]]))\n",
      "    \n",
      "    # The initial params for the algorithm (rough initialisaton)\n",
      "    initial_params = np.array([0, 0, bounds[0][0] + 0.5, bounds[0][1] + 0.5])\n",
      "    # A transform that applies the offset\n",
      "    offset_transform = Translation(np.array([bounds[0][0], bounds[0][1]]))\n",
      "    \n",
      "    # Run\n",
      "    for offset_idx in xrange(n_freq_tests):\n",
      "        # TODO: use pt_offset\n",
      "        # Perturb the original box by some small amount\n",
      "        target_box = PointCloud(original_box.points + np.random.uniform(-1, 1, (4, 2)) * spatial_sigma)\n",
      "        # Snap the affine perturbation back to a similarity transformation\n",
      "        target_transform = SimilarityTransform.align(original_box, target_box)\n",
      "        # Create the target box (not offset)\n",
      "        target_transform.apply_inplace(target_box)\n",
      "\n",
      "        # Warp original image to get test \"template\" image\n",
      "        template_mask = BooleanNDImage.blank((bounds_height, bounds_width))\n",
      "        # Compose with the offset so that it's at the correct position on the face\n",
      "        target = template.warp_to(template_mask, target_transform.compose_after(offset_transform))\n",
      "\n",
      "        if verbose:\n",
      "            print 'Initial RMS: {0}'.format(rms_point_error(original_box, target_box))\n",
      "        \n",
      "        # Run each algorithm\n",
      "        for i, option in enumerate(alg_list):\n",
      "            # Allow the passing of arguments in to the instantiated class\n",
      "            preprocess_func, metric = get_residual(option)\n",
      "            \n",
      "            processed_target = preprocess_func(target)\n",
      "            processed_img = preprocess_func(img)\n",
      "\n",
      "            iic = ImageInverseCompositional(processed_target, metric, SimilarityTransform(np.eye(3)), interpolator='c')\n",
      "            final_transform = iic.align(processed_img, initial_params, max_iters=n_iters)\n",
      "            # Create the estimated box\n",
      "            estimated_box = final_transform.apply(original_box)\n",
      "            # Make sure the original box is at the correct offset\n",
      "            rms_pt_error = rms_point_error(offset_transform.apply(original_box), estimated_box)\n",
      "\n",
      "            if verbose:\n",
      "                print '{0}: {1}'.format(option, rms_pt_error)\n",
      "\n",
      "            if not option in results:\n",
      "                results[option] = []\n",
      "            measure_results = results[option]\n",
      "            measure_results.append(rms_pt_error)\n",
      "            results[option] = measure_results\n",
      "\n",
      "    return results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load datasets\n",
      "np.set_printoptions(suppress=True, precision=3, linewidth=600)\n",
      "bosphorus_path = '/vol/hci2/Databases/video/Bosphorus/BosphorusDB/'\n",
      "subject_list = ['bs000']\n",
      "neutral_id = '_N_N_0'\n",
      "expression_list = ['_O_EYE_0', '_O_MOUTH_0', '_O_GLASSES_0', '_O_HAIR_0']\n",
      "\n",
      "num_of_subjs = len(subject_list)\n",
      "num_of_imgs_per_subj = len(expression_list)\n",
      "\n",
      "# Set up experiment variables\n",
      "verbose = True\n",
      "n_iters = 30                     # Number of gradient descent iterations\n",
      "n_freq_tests = 10                # Number of frequency of convergence tests\n",
      "max_spatial_error = 3.0          # Max location error for deciding convergence\n",
      "all_spc_sig = np.arange(1, 11)   # All spatial sigmas (1,10)\n",
      "\n",
      "alg_list = ['DEPTH', 'NORMAL']\n",
      "\n",
      "results = np.zeros([num_of_subjs, num_of_imgs_per_subj, len(all_spc_sig), len(alg_list)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# Run experiment for each subject\n",
      "for subj in xrange(num_of_subjs):\n",
      "    subject_id = subject_list[subj]\n",
      "    print 'Subject {} of ({}/{})'.format(subject_id, subj, num_of_subjs)\n",
      "    template = auto_import(os.path.join(bosphorus_path, subject_id, '{}{}.bnt'.format(subject_id, neutral_id)), verbose=False)[0]\n",
      "                       \n",
      "    for subj_img in xrange(num_of_imgs_per_subj):\n",
      "        expression_id = expression_list[subj_img]\n",
      "        img = auto_import(os.path.join(bosphorus_path, subject_id, '{}{}.bnt'.format(subject_id, expression_id)), verbose=False)[0]\n",
      "\n",
      "        template_labels = set(template.landmarks['LM2'].labels)\n",
      "        img_labels = set(img.landmarks['LM2'].labels)\n",
      "        matching_labels = template_labels.intersection(img_labels)\n",
      "        \n",
      "        template_points = template.landmarks['LM2'].with_labels(matching_labels).lms\n",
      "        img_points = img.landmarks['LM2'].with_labels(matching_labels).lms\n",
      "        \n",
      "        transform = SimilarityTransform.align(template_points, img_points)\n",
      "        \n",
      "        img = img.warp_to(BooleanNDImage.blank(template.shape), transform, warp_mask=True, warp_landmarks=True)\n",
      "        \n",
      "        template.landmarks['face'] = template.landmarks['LM2']#.with_labels(['middle_left_eyebrow',\n",
      "                                                              #              'middle_right_eyebrow',\n",
      "                                                              #              'lower_lip_outer_middle']).lms\n",
      "        \n",
      "        bounds = template.landmarks['face'].lms.bounds()\n",
      "        bounds_height, bounds_width = (bounds[1][1] - bounds[0][1], bounds[1][0] - bounds[0][0])\n",
      "        \n",
      "        tdata = lambda x: 0\n",
      "        tdata.template = template\n",
      "        tdata.img = img\n",
      "        tdata.bounds = bounds\n",
      "        tdata.bounds_height = bounds_height\n",
      "        tdata.bounds_width = bounds_width\n",
      "        \n",
      "        # Run tests\n",
      "        for sigma_ind, current_sigma in enumerate(all_spc_sig):\n",
      "            # TODO: generate pt_offset\n",
      "            res = my_test_affine(tdata, [], alg_list, n_iters, n_freq_tests, current_sigma, verbose)\n",
      "\n",
      "            for measure_ind, option in enumerate(alg_list):\n",
      "                measure_results = res[option]\n",
      "                # Get whether or not it converges\n",
      "                n_converge = len(filter(lambda error: error < max_spatial_error, measure_results))\n",
      "                results[subj, subj_img, sigma_ind, measure_ind] = n_converge\n",
      "\n",
      "\n",
      "# Save out results just in case\n",
      "scipy.io.savemat('results.mat', {'results': results})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot results\n",
      "mean_results = np.mean(np.mean(results, 1), 0) / float(n_freq_tests)\n",
      "\n",
      "\n",
      "line_styles = ['k--D', 'y:^', 'r:*', 'g:^', 'b-s']\n",
      "lines = []\n",
      "for i in xrange(mean_results.shape[1]):\n",
      "    lines.append(all_spc_sig)\n",
      "    lines.append(mean_results[:, i])\n",
      "    lines.append(line_styles[i])\n",
      "\n",
      "p = plt.plot(*lines)\n",
      "\n",
      "legend_labels = [a for a in alg_list.keys()]\n",
      "plt.yticks(np.linspace(0, 1, 11))\n",
      "plt.xticks(all_spc_sig)\n",
      "plt.ylabel('Frequency of Convergence')\n",
      "plt.xlabel('Point Standard Deviation')\n",
      "plt.legend(p, legend_labels)\n",
      "plt.title('Yale: with Smoothing')\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}