{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy.io\n",
      "import numpy as np\n",
      "from pybug.transform import SimilarityTransform, Translation\n",
      "from pybug.lucaskanade.image import ImageInverseCompositional\n",
      "from pybug.image import MaskedNDImage, BooleanNDImage\n",
      "import matplotlib.pyplot as plt\n",
      "from collections import OrderedDict\n",
      "from pybug.shape import PointCloud\n",
      "from pybug.io import auto_import\n",
      "import os"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 140
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def rms_point_error(original_box, transformed_box):\n",
      "    return np.sqrt(np.mean((original_box.points - transformed_box.points) ** 2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def build_normal_image(image):\n",
      "    n_image = MaskedNDImage.blank(image.shape, mask=image.mask, n_channels=3)\n",
      "    n_image.from_vector_inplace(image.mesh.vertex_normals.ravel())\n",
      "    return n_image"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pybug.lucaskanade import LSIntensity\n",
      "\n",
      "def get_residual(option):\n",
      "    if option == 'DEPTH':\n",
      "        return (lambda x: x, LSIntensity())\n",
      "    elif option == 'NORMAL':\n",
      "        return (build_normal_image, LSIntensity())\n",
      "    else:\n",
      "        raise ValueError('Unknown algorithm option')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def my_test_affine(tdata, pt_offsets, alg_list, n_iters, n_freq_tests, spatial_sigma, verbose):\n",
      "    results = {}\n",
      "    \n",
      "    bounds_height = tdata.bounds_height\n",
      "    bounds_width = tdata.bounds_width\n",
      "    bounds = tdata.bounds\n",
      "    img = tdata.img\n",
      "    template = tdata.template\n",
      "    \n",
      "    # The box that the face lives in (not offset to correct position)\n",
      "    original_box = PointCloud(np.array([[0,             0],\n",
      "                                        [bounds_height, 0],\n",
      "                                        [bounds_height, bounds_width],\n",
      "                                        [0,             bounds_width]]))\n",
      "    \n",
      "    # The initial params for the algorithm (rough initialisaton)\n",
      "    initial_params = np.array([0, 0, bounds[0][0] + 0.5, bounds[0][1] + 0.5])\n",
      "    # A transform that applies the offset\n",
      "    offset_transform = Translation(np.array([bounds[0][0], bounds[0][1]]))\n",
      "    \n",
      "    # Run\n",
      "    for offset_idx in xrange(n_freq_tests):\n",
      "        # TODO: use pt_offset\n",
      "        # Perturb the original box by some small amount\n",
      "        target_box = PointCloud(original_box.points + np.random.uniform(-1, 1, (4, 2)) * spatial_sigma)\n",
      "        # Snap the affine perturbation back to a similarity transformation\n",
      "        target_transform = SimilarityTransform.align(original_box, target_box)\n",
      "        # Create the target box (not offset)\n",
      "        target_transform.apply_inplace(target_box)\n",
      "\n",
      "        # Warp original image to get test \"template\" image\n",
      "        template_mask = BooleanNDImage.blank((bounds_height, bounds_width))\n",
      "        # Compose with the offset so that it's at the correct position on the face\n",
      "        target = template.warp_to(template_mask, target_transform.compose_after(offset_transform))\n",
      "\n",
      "        if verbose:\n",
      "            print 'Initial RMS: {0}'.format(rms_point_error(original_box, target_box))\n",
      "        \n",
      "        # Run each algorithm\n",
      "        for i, option in enumerate(alg_list):\n",
      "            # Allow the passing of arguments in to the instantiated class\n",
      "            preprocess_func, metric = get_residual(option)\n",
      "            \n",
      "            processed_target = preprocess_func(target)\n",
      "            processed_img = preprocess_func(img)\n",
      "\n",
      "            iic = ImageInverseCompositional(processed_target, metric, SimilarityTransform(np.eye(3)), interpolator='c')\n",
      "            final_transform = iic.align(processed_img, initial_params, max_iters=n_iters)\n",
      "            # Create the estimated box\n",
      "            estimated_box = final_transform.apply(original_box)\n",
      "            # Make sure the original box is at the correct offset\n",
      "            rms_pt_error = rms_point_error(offset_transform.apply(original_box), estimated_box)\n",
      "\n",
      "            if verbose:\n",
      "                print '{0}: {1}'.format(option, rms_pt_error)\n",
      "\n",
      "            if not option in results:\n",
      "                results[option] = []\n",
      "            measure_results = results[option]\n",
      "            measure_results.append(rms_pt_error)\n",
      "            results[option] = measure_results\n",
      "\n",
      "    return results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 144
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load datasets\n",
      "np.set_printoptions(suppress=True, precision=3, linewidth=600)\n",
      "bosphorus_path = '/vol/hci2/Databases/video/Bosphorus/BosphorusDB/'\n",
      "subject_list = ['bs000']\n",
      "neutral_id = '_N_N_0'\n",
      "expression_list = ['_O_EYE_0', '_O_MOUTH_0', '_O_GLASSES_0', '_O_HAIR_0']\n",
      "\n",
      "num_of_subjs = len(subject_list)\n",
      "num_of_imgs_per_subj = len(expression_list)\n",
      "\n",
      "# Set up experiment variables\n",
      "verbose = True\n",
      "n_iters = 30                     # Number of gradient descent iterations\n",
      "n_freq_tests = 10                # Number of frequency of convergence tests\n",
      "max_spatial_error = 3.0          # Max location error for deciding convergence\n",
      "all_spc_sig = np.arange(1, 11)   # All spatial sigmas (1,10)\n",
      "\n",
      "alg_list = ['DEPTH', 'NORMAL']\n",
      "\n",
      "results = np.zeros([num_of_subjs, num_of_imgs_per_subj, len(all_spc_sig), len(alg_list)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 147
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "# Run experiment for each subject\n",
      "for subj in xrange(num_of_subjs):\n",
      "    subject_id = subject_list[subj]\n",
      "    print 'Subject {} of ({}/{})'.format(subject_id, subj, num_of_subjs)\n",
      "    template = auto_import(os.path.join(bosphorus_path, subject_id, '{}{}.bnt'.format(subject_id, neutral_id)))[0]\n",
      "                       \n",
      "    for subj_img in xrange(num_of_imgs_per_subj):\n",
      "        expression_id = expression_list[subj_img]\n",
      "        img = auto_import(os.path.join(bosphorus_path, subject_id, '{}{}.bnt'.format(subject_id, expression_id)))[0]\n",
      "        img = template\n",
      "        template_labels = set(template.landmarks['LM2'].labels)\n",
      "        img_labels = set(img.landmarks['LM2'].labels)\n",
      "        matching_labels = template_labels.intersection(img_labels)\n",
      "        \n",
      "        template_points = template.landmarks['LM2'].with_labels(matching_labels).lms\n",
      "        img_points = img.landmarks['LM2'].with_labels(matching_labels).lms\n",
      "        \n",
      "        transform = SimilarityTransform.align(template_points, img_points)\n",
      "        \n",
      "        img = img.warp_to(BooleanNDImage.blank(template.shape), transform, warp_mask=True, warp_landmarks=True)\n",
      "        \n",
      "        template.landmarks['face'] = template.landmarks['LM2']#.with_labels(['middle_left_eyebrow',\n",
      "                                                              #              'middle_right_eyebrow',\n",
      "                                                              #              'lower_lip_outer_middle']).lms\n",
      "        \n",
      "        bounds = template.landmarks['face'].lms.bounds()\n",
      "        bounds_height, bounds_width = (bounds[1][1] - bounds[0][1], bounds[1][0] - bounds[0][0])\n",
      "        \n",
      "        tdata = lambda x: 0\n",
      "        tdata.template = template\n",
      "        tdata.img = img\n",
      "        tdata.bounds = bounds\n",
      "        tdata.bounds_height = bounds_height\n",
      "        tdata.bounds_width = bounds_width\n",
      "        \n",
      "        # Run tests\n",
      "        for sigma_ind, current_sigma in enumerate(all_spc_sig):\n",
      "            # TODO: generate pt_offset\n",
      "            res = my_test_affine(tdata, [], alg_list, n_iters, n_freq_tests, current_sigma, verbose)\n",
      "\n",
      "            for measure_ind, option in enumerate(alg_list):\n",
      "                measure_results = res[option]\n",
      "                # Get whether or not it converges\n",
      "                n_converge = len(filter(lambda error: error < max_spatial_error, measure_results))\n",
      "                results[subj, subj_img, sigma_ind, measure_ind] = n_converge\n",
      "\n",
      "\n",
      "# Save out results just in case\n",
      "scipy.io.savemat('results.mat', {'results': results})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Subject bs000 of (0/1)\n",
        "Found 1 files. (0/1) are importable\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Found 1 files. (1/1) are importable\n",
        "\r",
        "Creating importer for <pybug.io.spatial_image.BNTImporter object at 0x5b87a90> (1 of 1)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Found 1 files. (0/1) are importable\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Found 1 files. (1/1) are importable\n",
        "\r",
        "Creating importer for <pybug.io.spatial_image.BNTImporter object at 0x5b7aad0> (1 of 1)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Initial RMS: 0.849136979855\n",
        "DEPTH: 0.700005177584"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "NORMAL: 0.294735524634"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Initial RMS: 1.12391335245\n",
        "DEPTH: 0.42121397663"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "NORMAL: 0.429790742709"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Initial RMS: 1.20801148565\n",
        "DEPTH: 0.888593747793"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "NORMAL: 0.628803757029"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Initial RMS: 0.796369391822\n",
        "DEPTH: 0.514667341697"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "NORMAL: 0.320691586608"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Initial RMS: 0.685400279292\n",
        "DEPTH: 0.573623477965"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "NORMAL: 0.329106951148"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Initial RMS: 1.17655763233\n",
        "DEPTH: 0.905620183246"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "NORMAL: 0.59198154328"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Initial RMS: 0.967107584311\n",
        "DEPTH: 0.438757426732"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "NORMAL: 0.34073186147"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Initial RMS: 0.610232684354\n",
        "DEPTH: 0.494262532056"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-148-3b25b4ba7666>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0msigma_ind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_sigma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_spc_sig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[1;31m# TODO: generate pt_offset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmy_test_affine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malg_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_freq_tests\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_sigma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mmeasure_ind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moption\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malg_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-144-d6d8591390a8>\u001b[0m in \u001b[0;36mmy_test_affine\u001b[1;34m(tdata, pt_offsets, alg_list, n_iters, n_freq_tests, spatial_sigma, verbose)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[0miic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImageInverseCompositional\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessed_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSimilarityTransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meye\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterpolator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m             \u001b[0mfinal_transform\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessed_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_iters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m             \u001b[1;31m# Create the estimated box\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[0mestimated_box\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinal_transform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal_box\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/pts08/.virtualenvs/pybug/src/pybug/pybug/lucaskanade/base.pyc\u001b[0m in \u001b[0;36malign\u001b[1;34m(self, image, params, max_iters, **kwargs)\u001b[0m\n\u001b[0;32m    166\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_align\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_iters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mabc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/pts08/.virtualenvs/pybug/src/pybug/pybug/lucaskanade/image/base.pyc\u001b[0m in \u001b[0;36m_align\u001b[1;34m(self, max_iters)\u001b[0m\n\u001b[0;32m    142\u001b[0m             IWxp = self.image.warp_to(self.template.mask,\n\u001b[0;32m    143\u001b[0m                                       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m                                       interpolator=self._interpolator)\n\u001b[0m\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m             \u001b[1;31m# Compute steepest descent parameter updates.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/pts08/.virtualenvs/pybug/src/pybug/pybug/image/masked.pyc\u001b[0m in \u001b[0;36mwarp_to\u001b[1;34m(self, template_mask, transform, warp_landmarks, warp_mask, interpolator, **kwargs)\u001b[0m\n\u001b[0;32m    385\u001b[0m                                                \u001b[0mwarp_landmarks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwarp_landmarks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m                                                \u001b[0minterpolator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minterpolator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m                                                **kwargs)\n\u001b[0m\u001b[0;32m    388\u001b[0m         \u001b[1;31m# note that _build_warped_image for MaskedNDImage classes attaches\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m         \u001b[1;31m# the template mask by default. If the user doesn't want to warp the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/pts08/.virtualenvs/pybug/src/pybug/pybug/image/base.pyc\u001b[0m in \u001b[0;36mwarp_to\u001b[1;34m(self, template_mask, transform, warp_landmarks, interpolator, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m                 \"(they must match)\".format(self.n_dims, transform.n_dims))\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m         \u001b[0mtemplate_points\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtemplate_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrue_indices\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[0mpoints_to_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemplate_points\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m         \u001b[1;31m# we want to sample each channel in turn, returning a vector of sampled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/pts08/.virtualenvs/pybug/src/pybug/pybug/image/boolean.pyc\u001b[0m in \u001b[0;36mtrue_indices\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m         \"\"\"\n\u001b[0;32m    119\u001b[0m         \u001b[1;31m# Ignore the channel axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpixels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/numpy/core/fromnumeric.pyc\u001b[0m in \u001b[0;36mnonzero\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m   1248\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'nonzero'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1249\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1250\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1251\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 148
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot results\n",
      "mean_results = np.mean(np.mean(results, 1), 0) / float(n_freq_tests)\n",
      "\n",
      "\n",
      "line_styles = ['k--D', 'y:^', 'r:*', 'g:^', 'b-s']\n",
      "lines = []\n",
      "for i in xrange(mean_results.shape[1]):\n",
      "    lines.append(all_spc_sig)\n",
      "    lines.append(mean_results[:, i])\n",
      "    lines.append(line_styles[i])\n",
      "\n",
      "p = plt.plot(*lines)\n",
      "\n",
      "legend_labels = [a for a in alg_list.keys()]\n",
      "plt.yticks(np.linspace(0, 1, 11))\n",
      "plt.xticks(all_spc_sig)\n",
      "plt.ylabel('Frequency of Convergence')\n",
      "plt.xlabel('Point Standard Deviation')\n",
      "plt.legend(p, legend_labels)\n",
      "plt.title('Yale: with Smoothing')\n",
      "\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}